{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93f6be5c",
   "metadata": {},
   "source": [
    "## Experiments with STFT preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e787eada",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e6d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D, Conv2D\n",
    "from keras.layers import MaxPooling1D, MaxPooling2D\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from pyroomacoustics.transform import stft\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c5c60d",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4127a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label resolution of classification\n",
    "RESOLUTION = 1\n",
    "\n",
    "# Number of samples to include while creating one ML feature\n",
    "SAMPLES = 256\n",
    "\n",
    "# Determines the overlap of samples between consecutive features\n",
    "STEP = 1024\n",
    "\n",
    "AUDIO_PATH = '../training_data/audio'\n",
    "\n",
    "# Number of microphones on the array\n",
    "MICS_NUMBER = 6\n",
    "\n",
    "MIC_COMBS = len(list(combinations(range(MICS_NUMBER), 2)))\n",
    "\n",
    "# Training rooms dimensions\n",
    "ROOMS = {\n",
    "    'small' : np.array([4, 4, 3]),\n",
    "    'medium' : np.array([6, 6, 3]),\n",
    "    'large' : np.array([8, 8, 3])\n",
    "}\n",
    "\n",
    "# Testing rooms dimensions\n",
    "TEST_ROOMS = {\n",
    "    'small' : np.array([5, 5, 2]),\n",
    "    'medium' : np.array([7, 7, 2]),\n",
    "    'large' : np.array([9, 9, 2])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2658fa04",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3babeff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_observations(wav_signals, fs, label, samples=1, step=1, resolution=20, music=False):\n",
    "    \"\"\"\n",
    "    Create list of observations from the pandas dataframe.\n",
    "    Each observation will be a STFT matrix, where each row \n",
    "    is a vector of STFT for a given microphone.\n",
    "    \n",
    "    Returns: \n",
    "        a tuple of observations and their corresponding labels\n",
    "    \"\"\"\n",
    "    rounded_label = round(label / resolution) * resolution\n",
    "    if rounded_label == 360: rounded_label = 0\n",
    "        \n",
    "    X = tf.signal.stft(wav_signals.astype(float).T, frame_length=SAMPLES, frame_step=STEP)\n",
    "    X = np.transpose(X, axes=[1, 0, 2])\n",
    "    y = [rounded_label] * len(X)\n",
    "    \n",
    "    return np.angle(X), y\n",
    "\n",
    "\n",
    "def create_whole_dataset(df_train, df_test, encoder, room=None, dist=None):\n",
    "    \"\"\"\n",
    "    Creates an entire dataset by extracting values\n",
    "    from train and tests dataframes.\n",
    "    \n",
    "    One-hot encodes the labels before returning.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Can filter testing entries to only check performance\n",
    "    # for given conditions\n",
    "    if room:\n",
    "        df_test = df_test[df_test.room == room]\n",
    "    if dist:\n",
    "        df_test = df_test[df_test.dist == dist]\n",
    "    \n",
    "    # Create train/test observations\n",
    "    X_train = df_train.drop(columns=['dist', 'room', 'label']).values.reshape(\n",
    "        len(df_train), -1, MICS_NUMBER, order='F')\n",
    "    X_test = df_test.drop(columns=['dist', 'room', 'label']).values.reshape(\n",
    "        len(df_test), -1, MICS_NUMBER, order='F')\n",
    "    \n",
    "    # Create train/test labels\n",
    "    y_train = df_train.label.values.reshape(-1, 1)\n",
    "    y_test = df_test.label.values.reshape(-1, 1)\n",
    "    \n",
    "    encoder.fit(y_train)\n",
    "    \n",
    "    y_train, y_test = encoder.transform(y_train), encoder.transform(y_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def create_dataframe(subset, plane='horizontal', samples=20, step=5, resolution=20, noise=False):\n",
    "    files = [file for file in os.listdir(os.path.join(AUDIO_PATH, plane)) if subset in file]\n",
    "    files = [file for file in files if (noise and 'white_noise' in file) or (not noise and not 'white_noise' in file)]\n",
    "    dataframes = []\n",
    "\n",
    "    # Loop through all WAVs\n",
    "    for i, file in enumerate(files):\n",
    "        if file[-3:] != 'wav': \n",
    "            continue\n",
    "            \n",
    "        print(f'{subset} file {i+1}/{len(files)}', end='\\r')\n",
    "\n",
    "        path = os.path.join(AUDIO_PATH, plane, file)\n",
    "        fs, wav_signals = wavfile.read(path)\n",
    "        \n",
    "        label = int(file.split('_')[2])\n",
    "        \n",
    "        # Create observations from a given WAV file\n",
    "        X_temp, y_temp = create_observations(wav_signals, fs, label, samples, step, resolution)\n",
    "        \n",
    "        cols = [\n",
    "            f'mic{mic+1}_{i}' \n",
    "                for mic in range(MICS_NUMBER)\n",
    "                    for i in range(np.shape(X_temp)[2])\n",
    "        ]\n",
    "        \n",
    "        df = pd.DataFrame(data=np.reshape(X_temp, (len(X_temp), -1)), columns=cols)\n",
    "        dist = int(file.split('_')[4])\n",
    "        room = file.split('_')[6]\n",
    "        df['dist'], df['room'] = dist, room\n",
    "            \n",
    "        # Add label column\n",
    "        df['label'] = y_temp\n",
    "        dataframes.append(df)\n",
    "        \n",
    "    return pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7af786",
   "metadata": {},
   "source": [
    "Generate training data on white noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d10e629a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train file 3240/3240\n",
      "test file 3240/3240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((425160, 129, 6), (216388, 129, 6), (425160, 360), (216388, 360))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_dataframe('train', samples=SAMPLES, step=STEP, resolution=RESOLUTION, noise=True)\n",
    "print()\n",
    "df_test = create_dataframe('test', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "print()\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "X_train, y_train, X_test, y_test = create_whole_dataset(df_train, df_test, encoder)\n",
    "np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6520eab",
   "metadata": {},
   "source": [
    "### Model trained on white noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520e3918",
   "metadata": {},
   "source": [
    "Implement a generator to read data from CSV in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(file_path, batch_size):\n",
    "    while True:\n",
    "        df_iterator = pd.read_csv(file_path, iterator=True, chunksize=batch_size)\n",
    "        for df in df_iterator:\n",
    "            X = df.drop(columns=['dist', 'room', 'label']).values.reshape(batch_size, -1, MICS_NUMBER, order='F')\n",
    "            X = np.transpose(np.array([X]), axes=[1, 2, 3, 0])\n",
    "            y = df.label.values.reshape(-1, 1)\n",
    "            y = encoder.transform(y)\n",
    "            yield X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7db118",
   "metadata": {},
   "source": [
    "Train the model with white noise generated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19963adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "epochs, batch_size, verbose = 20, 32, 1\n",
    "# steps_per_epoch = train_rows // batch_size\n",
    "\n",
    "def create_model(X_train, y_train, X_test, y_test):\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "\n",
    "    # Init model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add layers\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, verbose=verbose, batch_size=batch_size)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f11c350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13287/13287 [==============================] - 100s 7ms/step - loss: 2.1205 - accuracy: 0.2553\n",
      "Epoch 2/20\n",
      "13287/13287 [==============================] - 87s 7ms/step - loss: 1.4021 - accuracy: 0.4070\n",
      "Epoch 3/20\n",
      "13287/13287 [==============================] - 91s 7ms/step - loss: 1.2687 - accuracy: 0.4605\n",
      "Epoch 4/20\n",
      "13287/13287 [==============================] - 92s 7ms/step - loss: 1.1799 - accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "13287/13287 [==============================] - 92s 7ms/step - loss: 1.1161 - accuracy: 0.5295\n",
      "Epoch 6/20\n",
      "13287/13287 [==============================] - 92s 7ms/step - loss: 1.0683 - accuracy: 0.5540\n",
      "Epoch 7/20\n",
      "13287/13287 [==============================] - 92s 7ms/step - loss: 1.0252 - accuracy: 0.5752\n",
      "Epoch 8/20\n",
      "13287/13287 [==============================] - 92s 7ms/step - loss: 0.9876 - accuracy: 0.5942\n",
      "Epoch 9/20\n",
      "13287/13287 [==============================] - 91s 7ms/step - loss: 0.9619 - accuracy: 0.6087\n",
      "Epoch 10/20\n",
      "13287/13287 [==============================] - 92s 7ms/step - loss: 0.9364 - accuracy: 0.6212\n",
      "Epoch 11/20\n",
      "13287/13287 [==============================] - 92s 7ms/step - loss: 0.9141 - accuracy: 0.6341\n",
      "Epoch 12/20\n",
      "13287/13287 [==============================] - 92s 7ms/step - loss: 0.8926 - accuracy: 0.6443\n",
      "Epoch 13/20\n",
      "13287/13287 [==============================] - 91s 7ms/step - loss: 0.8769 - accuracy: 0.6536\n",
      "Epoch 14/20\n",
      "13287/13287 [==============================] - 90s 7ms/step - loss: 0.8643 - accuracy: 0.6613\n",
      "Epoch 15/20\n",
      "13287/13287 [==============================] - 86s 6ms/step - loss: 0.8511 - accuracy: 0.6680\n",
      "Epoch 16/20\n",
      "13287/13287 [==============================] - 85s 6ms/step - loss: 0.8411 - accuracy: 0.6720\n",
      "Epoch 17/20\n",
      "13287/13287 [==============================] - 87s 7ms/step - loss: 0.8343 - accuracy: 0.6771\n",
      "Epoch 18/20\n",
      "13287/13287 [==============================] - 89s 7ms/step - loss: 0.8254 - accuracy: 0.6816\n",
      "Epoch 19/20\n",
      "13287/13287 [==============================] - 87s 7ms/step - loss: 0.8223 - accuracy: 0.6849\n",
      "Epoch 20/20\n",
      "13287/13287 [==============================] - 87s 7ms/step - loss: 0.8150 - accuracy: 0.6900\n"
     ]
    }
   ],
   "source": [
    "model, _ = create_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb7db7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6763/6763 [==============================] - 26s 4ms/step - loss: 2.9721 - accuracy: 0.4976\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f9eb62",
   "metadata": {},
   "source": [
    "Evaluate performance for different properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e51dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_for_property(df_train, df_test, model, prop, value):\n",
    "    \"\"\"\n",
    "    Measures the model prediction for test samples\n",
    "    with a given property, such as room size.\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    \n",
    "    # Filter test set by property value\n",
    "    X_trn, y_trn, X_tst, y_tst = create_whole_dataset(\n",
    "        df_train, df_test[df_test[prop]==value], encoder\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on the filtered set\n",
    "    loss, acc = model.evaluate(X_tst, y_tst, batch_size=batch_size, verbose=0)\n",
    "    return round(loss, 3), round(acc, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b701e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Room sizes\n",
      "small room accuracy: 0.479\n",
      "medium room accuracy: 0.502\n",
      "large room accuracy: 0.511\n",
      "\n",
      "Distances\n",
      "50 cm distance accuracy: 0.34\n",
      "150 cm distance accuracy: 0.572\n",
      "200 cm distance accuracy: 0.565\n",
      "250 cm distance accuracy: 0.569\n",
      "350 cm distance accuracy: 0.595\n",
      "450 cm distance accuracy: 0.587\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance for different properties\n",
    "print('Room sizes')\n",
    "for room in ROOMS:\n",
    "    _, acc = evaluate_for_property(df_train, df_test, model, 'room', room)\n",
    "    print(f\"{room} room accuracy: {acc}\")\n",
    "    \n",
    "print('\\nDistances')\n",
    "for dist in np.unique(df_test.dist):\n",
    "    _, acc = evaluate_for_property(df_train, df_test, model, 'dist', dist)\n",
    "    print(f\"{dist} cm distance accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a95e7",
   "metadata": {},
   "source": [
    "### Model trained on real audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70493c36",
   "metadata": {},
   "source": [
    "Generate training data on real audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9ee32b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train file 3240/3240\n",
      "test file 3240/3240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((634196, 129, 6), (216388, 129, 6), (634196, 360), (216388, 360))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_dataframe('train', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "print()\n",
    "df_test = create_dataframe('test', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "print()\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "X_train, y_train, X_test, y_test = create_whole_dataset(df_train, df_test, encoder)\n",
    "np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da51d78f",
   "metadata": {},
   "source": [
    "Train the model on real audio generated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "384f6da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19819/19819 [==============================] - 150s 7ms/step - loss: 1.9349 - accuracy: 0.2926\n",
      "Epoch 2/20\n",
      "19819/19819 [==============================] - 140s 7ms/step - loss: 1.3460 - accuracy: 0.4357\n",
      "Epoch 3/20\n",
      "19819/19819 [==============================] - 133s 7ms/step - loss: 1.2076 - accuracy: 0.4941\n",
      "Epoch 4/20\n",
      "19819/19819 [==============================] - 137s 7ms/step - loss: 1.1271 - accuracy: 0.5335\n",
      "Epoch 5/20\n",
      "19819/19819 [==============================] - 139s 7ms/step - loss: 1.0697 - accuracy: 0.5630\n",
      "Epoch 6/20\n",
      "19819/19819 [==============================] - 141s 7ms/step - loss: 1.0294 - accuracy: 0.5850\n",
      "Epoch 7/20\n",
      "19819/19819 [==============================] - 140s 7ms/step - loss: 0.9947 - accuracy: 0.6029\n",
      "Epoch 8/20\n",
      "19819/19819 [==============================] - 138s 7ms/step - loss: 0.9651 - accuracy: 0.6208\n",
      "Epoch 9/20\n",
      "19819/19819 [==============================] - 134s 7ms/step - loss: 0.9438 - accuracy: 0.6316\n",
      "Epoch 10/20\n",
      "19819/19819 [==============================] - 138s 7ms/step - loss: 0.9246 - accuracy: 0.6430\n",
      "Epoch 11/20\n",
      "19819/19819 [==============================] - 127s 6ms/step - loss: 0.9177 - accuracy: 0.6484\n",
      "Epoch 12/20\n",
      "19819/19819 [==============================] - 127s 6ms/step - loss: 0.9064 - accuracy: 0.6550\n",
      "Epoch 13/20\n",
      "19819/19819 [==============================] - 130s 7ms/step - loss: 0.9011 - accuracy: 0.6594\n",
      "Epoch 14/20\n",
      "19819/19819 [==============================] - 132s 7ms/step - loss: 0.8943 - accuracy: 0.6644\n",
      "Epoch 15/20\n",
      "19819/19819 [==============================] - 133s 7ms/step - loss: 0.8897 - accuracy: 0.6686\n",
      "Epoch 16/20\n",
      "19819/19819 [==============================] - 133s 7ms/step - loss: 0.8837 - accuracy: 0.6717\n",
      "Epoch 17/20\n",
      "19819/19819 [==============================] - 134s 7ms/step - loss: 0.8932 - accuracy: 0.6714\n",
      "Epoch 18/20\n",
      "19819/19819 [==============================] - 133s 7ms/step - loss: 0.8947 - accuracy: 0.6724\n",
      "Epoch 19/20\n",
      "19819/19819 [==============================] - 129s 7ms/step - loss: 0.8988 - accuracy: 0.6725\n",
      "Epoch 20/20\n",
      "19819/19819 [==============================] - 130s 7ms/step - loss: 0.9031 - accuracy: 0.6733\n"
     ]
    }
   ],
   "source": [
    "model, _ = create_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e65a6b7",
   "metadata": {},
   "source": [
    "Evaluate new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6ecfe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6763/6763 [==============================] - 25s 4ms/step - loss: 2.4250 - accuracy: 0.5013\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcddfc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Room sizes\n",
      "small room accuracy: 0.485\n",
      "medium room accuracy: 0.499\n",
      "large room accuracy: 0.519\n",
      "\n",
      "Distances\n",
      "50 cm distance accuracy: 0.362\n",
      "150 cm distance accuracy: 0.559\n",
      "200 cm distance accuracy: 0.553\n",
      "250 cm distance accuracy: 0.581\n",
      "350 cm distance accuracy: 0.577\n",
      "450 cm distance accuracy: 0.573\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance for different properties\n",
    "print('Room sizes')\n",
    "for room in ROOMS:\n",
    "    _, acc = evaluate_for_property(df_train, df_test, model, 'room', room)\n",
    "    print(f\"{room} room accuracy: {acc}\")\n",
    "    \n",
    "print('\\nDistances')\n",
    "for dist in np.unique(df_test.dist):\n",
    "    _, acc = evaluate_for_property(df_train, df_test, model, 'dist', dist)\n",
    "    print(f\"{dist} cm distance accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37796ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 127, 64)           1216      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 125, 64)           12352     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              8193024   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 360)               369000    \n",
      "=================================================================\n",
      "Total params: 9,625,192\n",
      "Trainable params: 9,625,192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7202135a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/stft_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../models/stft_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
