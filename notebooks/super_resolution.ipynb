{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22976b0e",
   "metadata": {},
   "source": [
    "# CNN DOA with 1 degree resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec58991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "from training import rmse\n",
    "from music import get_all_predictions\n",
    "from training import create_model, evaluate_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "from pyroomacoustics.transform import stft\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten, Reshape\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D, Conv2D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import LSTM\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1)\n",
    "\n",
    "from numba import cuda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ecb62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label resolution of classification\n",
    "RESOLUTION = 1\n",
    "\n",
    "# Number of samples to include while creating one ML feature\n",
    "SAMPLES = 2048\n",
    "\n",
    "# Determines the overlap of samples between consecutive features\n",
    "STEP = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd9f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcc_phat(x_1, x_2, FS=16000, interp=1):\n",
    "    \"\"\"\n",
    "    Function that will compute the GCC-PHAT\n",
    "    cross-correlation of two separate audio channels\n",
    "    \n",
    "    Returns:\n",
    "        A 1-D GCC vector\n",
    "    \"\"\"\n",
    "    \n",
    "    n = len(x_1) + len(x_2) - 1\n",
    "    n += 1 if n % 2 else 0\n",
    "    \n",
    "    # Fourier transforms of the two signals\n",
    "    X_1 = np.fft.rfft(x_1, n=n)\n",
    "    X_2 = np.fft.rfft(x_2, n=n)\n",
    "    \n",
    "     # Normalize by the magnitude of FFT - because PHAT\n",
    "    np.divide(X_1, np.abs(X_1), X_1, where=np.abs(X_1) != 0)\n",
    "    np.divide(X_2, np.abs(X_2), X_2, where=np.abs(X_2) != 0)\n",
    "    \n",
    "    # GCC-PHAT = [X_1(f)X_2*(f)] / |X_1(f)X_2*(f)|\n",
    "    # See http://www.xavieranguera.com/phdthesis/node92.html for reference\n",
    "    CC = X_1 * np.conj(X_2)\n",
    "    cc = np.fft.irfft(CC, n=n * interp)\n",
    "        \n",
    "    # Maximum delay between a pair of microphones,\n",
    "    # expressed in a number of samples.\n",
    "    # 0.09 m is the mic array diameter and \n",
    "    # 340 m/s is assumed to be the speed of sound.\n",
    "    max_len = math.ceil(0.09 / 340 * FS * interp)\n",
    "    \n",
    "    # Trim the cc vector to only include a \n",
    "    # small number of samples around the origin\n",
    "    cc = np.concatenate((cc[-max_len:], cc[:max_len+1]))\n",
    "    \n",
    "    # Return the cross correlation\n",
    "    return cc\n",
    "\n",
    "\n",
    "def compute_gcc_matrix(observation, fs, interp=1):\n",
    "    \"\"\"\n",
    "    Creates a GCC matrix, where each row is a vector of GCC \n",
    "    between a given pair of microphones.\n",
    "    \"\"\" \n",
    "    \n",
    "    mic_pairs = combinations(range(MICS_NUMBER), r=2)\n",
    "\n",
    "    # Initialize a transformed observation, that will be populated with GCC vectors\n",
    "    # of the observation\n",
    "    transformed_observation = []\n",
    "\n",
    "    # Compute GCC for every pair of microphones\n",
    "    for mic_1, mic_2 in mic_pairs:\n",
    "        x_1 = observation[:, mic_1]\n",
    "        x_2 = observation[:, mic_2]\n",
    "\n",
    "        gcc = gcc_phat(x_1, x_2, FS=fs, interp=interp)\n",
    "\n",
    "        # Add the GCC vector to the GCC matrix\n",
    "        transformed_observation.append(gcc)    \n",
    "        \n",
    "    return transformed_observation\n",
    "\n",
    "\n",
    "def compute_stft_matrix(observation, nfft=256):\n",
    "    \"\"\"\n",
    "    Creates a STFT matrix using microphone data from 6 channels.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Default value for overlap\n",
    "    step = nfft // 2\n",
    "    \n",
    "    # Calculate multidimensional STFT and return\n",
    "    transformed_observation = stft.analysis(observation, L=nfft, hop=step)\n",
    "    return np.transpose(transformed_observation, axes=[2, 1, 0])\n",
    "\n",
    "\n",
    "def create_observations(wav_signals, fs, label, samples=1, step=1, resolution=20, music=False, interp=1):\n",
    "    \"\"\"\n",
    "    Create list of observations from the pandas dataframe.\n",
    "    Each observation will be a GCC matrix, where each row \n",
    "    is a vector of GCC between a given pair of microphones.\n",
    "    \n",
    "    Returns: \n",
    "        a tuple of observations and their corresponding labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lists of observations and labels that will be populated\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    rounded_label = round(label / resolution) * resolution\n",
    "    if rounded_label == 360: rounded_label = 0\n",
    "    \n",
    "    # Loop through the signal frame and take subframes\n",
    "    for i in range(0, len(wav_signals) - samples + 1, step):\n",
    "        y.append(rounded_label)\n",
    "        \n",
    "        # Extract the observation from subframe\n",
    "        observation = np.array(wav_signals[i : i + samples])\n",
    "        \n",
    "        if music:\n",
    "            # Transform observation into a STFT matrix\n",
    "            transformed_observation = compute_stft_matrix(observation)\n",
    "        else:\n",
    "            # Transform observation into a GCC matrix\n",
    "            transformed_observation = compute_gcc_matrix(observation, fs, interp=interp)\n",
    "            \n",
    "        X.append(transformed_observation)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def one_hot_encode(encoder, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Creates a one-hot encoding of categorical labels\n",
    "    provided in y_train and y_test.\n",
    "    \"\"\"\n",
    "    \n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "    \n",
    "    # One-hot encode training and testing labels\n",
    "    enc = encoder.fit(y_train)\n",
    "    y_train = enc.transform(y_train)\n",
    "    y_test = enc.transform(y_test)\n",
    "    \n",
    "    return y_train, y_test\n",
    "  \n",
    "    \n",
    "def create_whole_dataset(df_train, df_test, encoder, room=None, dist=None):\n",
    "    \"\"\"\n",
    "    Creates an entire dataset by extracting values\n",
    "    from train and tests dataframes.\n",
    "    \n",
    "    One-hot encodes the labels before returning.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Can filter testing entries to only check performance\n",
    "    # for given conditions\n",
    "    if room:\n",
    "        df_test = df_test[df_test.room == room]\n",
    "    if dist:\n",
    "        df_test = df_test[df_test.dist == dist]\n",
    "    \n",
    "    # Create train/test observations\n",
    "    X_train = df_train.drop(columns=['dist', 'room', 'label']).values.reshape(\n",
    "        len(df_train), MIC_COMBS, -1)\n",
    "    X_test = df_test.drop(columns=['dist', 'room', 'label']).values.reshape(\n",
    "        len(df_test), MIC_COMBS, -1)\n",
    "    \n",
    "    # Create train/test labels\n",
    "    y_train, y_test = one_hot_encode(\n",
    "        encoder, df_train['label'].values, df_test['label'].values)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def create_dataframe(subset, plane='horizontal', samples=20, step=5, resolution=20, interp=1):\n",
    "    dataframes = []\n",
    "    \n",
    "    files = [file for file in os.listdir(os.path.join(AUDIO_PATH, plane)) if subset in file and 'white_noise' not in file]\n",
    "\n",
    "    # Loop through all WAVs\n",
    "    for i, file in enumerate(files):\n",
    "        if file[-3:] != 'wav': \n",
    "            continue\n",
    "            \n",
    "        print(f'{subset} file {i+1}/{len(files)}', end='\\r')\n",
    "\n",
    "        path = os.path.join(AUDIO_PATH, plane, file)\n",
    "        fs, wav_signals = wavfile.read(path)\n",
    "        \n",
    "        label = int(file.split('_')[2])\n",
    "        \n",
    "        # Create observations from a given WAV file\n",
    "        X_temp, y_temp = create_observations(wav_signals, fs, label, samples, step, resolution, interp=interp)\n",
    "        \n",
    "        cols = [\n",
    "            f'mics{mic_1+1}{mic_2+1}_{i}' \n",
    "                for mic_1, mic_2 in combinations(range(MICS_NUMBER), r=2) \n",
    "                    for i in range(np.shape(X_temp)[2])\n",
    "        ]\n",
    "        \n",
    "        df = pd.DataFrame(data=np.reshape(X_temp, (len(X_temp), -1)), columns=cols)\n",
    "        dist = int(file.split('_')[4])\n",
    "        room = file.split('_')[6]\n",
    "        df['dist'], df['room'] = dist, room\n",
    "            \n",
    "        # Add label column\n",
    "        df['label'] = y_temp\n",
    "        dataframes.append(df)\n",
    "        \n",
    "    return pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff00a40d",
   "metadata": {},
   "source": [
    "### Create training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "358a241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train file 3240/3240\n",
      "test file 3240/3240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((628560, 15, 25), (210740, 15, 25), (628560, 360), (210740, 360))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_dataframe('train', samples=SAMPLES, step=STEP, resolution=RESOLUTION, interp=2)\n",
    "print()\n",
    "df_test = create_dataframe('test', samples=SAMPLES, step=STEP, resolution=RESOLUTION, interp=2)\n",
    "print()\n",
    "\n",
    "df_train.to_csv('../training_data/super_azimuth_train_dataset.csv')\n",
    "df_test.to_csv('../training_data/super_azimuth_test_dataset.csv')\n",
    "\n",
    "# Create numpy arrays with observations and one-hot labels\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "X_train, y_train, X_test, y_test = create_whole_dataset(df_train, df_test, encoder)\n",
    "\n",
    "np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ddba82",
   "metadata": {},
   "source": [
    "Only run this when all the variables are not stored in memory (i.e. after restarting the kernel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eae0e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((628560, 15, 25), (210740, 15, 25), (628560, 360), (210740, 360))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../training_data/super_azimuth_train_dataset.csv', index_col=[0])\n",
    "df_test = pd.read_csv('../training_data/super_azimuth_test_dataset.csv', index_col=[0])\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "encoder.fit([[label] for label in df_train['label']])\n",
    "X_train, y_train, X_test, y_test = create_whole_dataset(df_train, df_test, encoder)\n",
    "np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19ad7797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gccs(angle_labels, observations):\n",
    "    # Create a 2x2 subplot\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10,10))\n",
    "    fig.suptitle('Example GCC matrices for different angles', fontsize=18)\n",
    "\n",
    "    for i, label in enumerate(np.unique(angle_labels)[::90]):\n",
    "        ax = axs[i//2][i%2]\n",
    "        indices = np.where(angle_labels == label)[0]\n",
    "        obs_idx = indices[np.random.randint(len(indices))]\n",
    "\n",
    "        observation = observations[obs_idx]\n",
    "\n",
    "        ax.set_title(f'Angle {label}')\n",
    "        im = ax.matshow(observation.T, aspect=0.5)\n",
    "        fig.colorbar(im, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a9fe5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get training labels\n",
    "angle_labels = encoder.inverse_transform(y_train)\n",
    "plot_gccs(angle_labels, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3755ab",
   "metadata": {},
   "source": [
    "### Fit and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df8586fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((628560, 25, 15), (210740, 25, 15))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose the observations because Conv1D requires timesteps as the 1st dim\n",
    "if X_train.shape[1] == MIC_COMBS:\n",
    "    X_train, X_test = np.transpose(X_train, axes=[0, 2, 1]), np.transpose(X_test, axes=[0, 2, 1])\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47903943",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, batch_size, verbose = 10, 32, 1\n",
    "\n",
    "# Fit model\n",
    "def create_model(X_train, y_train, X_test, y_test, cnn_layers=5, pooling=True, lstm=False):\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "\n",
    "    # Init model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add layers\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    \n",
    "    for i in range(cnn_layers-1):\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "        \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    if pooling:\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        \n",
    "    if lstm:\n",
    "        model.add(LSTM(128, return_sequences=True))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dd45f2",
   "metadata": {},
   "source": [
    "Five conv. layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76c37d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 132s 6ms/step - loss: 1.2076 - accuracy: 0.5082\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 121s 6ms/step - loss: 0.6595 - accuracy: 0.7333\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 121s 6ms/step - loss: 0.5163 - accuracy: 0.8014\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 121s 6ms/step - loss: 0.4427 - accuracy: 0.8346\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 121s 6ms/step - loss: 0.4039 - accuracy: 0.8523\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 121s 6ms/step - loss: 0.3797 - accuracy: 0.8633\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 121s 6ms/step - loss: 0.3626 - accuracy: 0.8716\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 122s 6ms/step - loss: 0.3455 - accuracy: 0.8790\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 121s 6ms/step - loss: 0.3364 - accuracy: 0.8831\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 121s 6ms/step - loss: 0.3288 - accuracy: 0.8870\n"
     ]
    }
   ],
   "source": [
    "model, history = create_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f41b7c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../models/super_history.npy', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7d4d6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6586/6586 [==============================] - 24s 4ms/step - loss: 0.5749 - accuracy: 0.8259\n",
      "Accuracy: 0.826\n",
      "RMSE: 6.744\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "accuracy = evaluate_model(model, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "y_pred_nn = encoder.inverse_transform(model.predict(X_test))\n",
    "y_true_nn = encoder.inverse_transform(y_test)\n",
    "print(f'RMSE: {rmse(y_true_nn, y_pred_nn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f84721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_for_property(df_train, df_test, prop, value):\n",
    "    \"\"\"\n",
    "    Measures the model prediction for test samples\n",
    "    with a given property, such as room size.\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    \n",
    "    # Filter test set by property value\n",
    "    X_trn, y_trn, X_tst, y_tst = create_whole_dataset(\n",
    "        df_train, df_test[df_test[prop]==value], encoder\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on the filtered set\n",
    "    X_tst = np.transpose(X_tst, axes=[0, 2, 1])\n",
    "    loss, acc = model.evaluate(X_tst, y_tst, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    return round(loss, 3), round(acc, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43dbe02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Room sizes\n",
      "small room accuracy: 0.823\n",
      "medium room accuracy: 0.825\n",
      "large room accuracy: 0.83\n",
      "\n",
      "Distances\n",
      "50 cm distance accuracy: 0.597\n",
      "150 cm distance accuracy: 0.942\n",
      "200 cm distance accuracy: 0.941\n",
      "250 cm distance accuracy: 0.934\n",
      "350 cm distance accuracy: 0.937\n",
      "450 cm distance accuracy: 0.949\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance for different properties\n",
    "print('Room sizes')\n",
    "for room in ROOMS:\n",
    "    _, acc = evaluate_for_property(df_train, df_test, 'room', room)\n",
    "    print(f\"{room} room accuracy: {acc}\")\n",
    "    \n",
    "print('\\nDistances')\n",
    "for dist in np.unique(df_test.dist):\n",
    "    _, acc = evaluate_for_property(df_train, df_test, 'dist', dist)\n",
    "    print(f\"{dist} cm distance accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3efb573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 23, 64)            2944      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 21, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 19, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 17, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 15, 64)            12352     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              449000    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 360)               360360    \n",
      "=================================================================\n",
      "Total params: 861,712\n",
      "Trainable params: 861,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1efcce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/super_model\\assets\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\tkhor\\AppData\\Local\\Temp\\tmpasv7b1lj\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../models/super_model\")\n",
    "\n",
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the Lite model.\n",
    "with open('../models/super_azimuth_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db29e077",
   "metadata": {},
   "source": [
    "### Run experiment with different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a74d6a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model with 2 convolutional layers ===\n",
      "Max pooling: True\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 131s 7ms/step - loss: 1.2995 - accuracy: 0.4711\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 125s 6ms/step - loss: 0.8245 - accuracy: 0.6487\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 126s 6ms/step - loss: 0.7080 - accuracy: 0.7052\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 133s 7ms/step - loss: 0.6441 - accuracy: 0.7352\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 130s 7ms/step - loss: 0.6018 - accuracy: 0.7563\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 130s 7ms/step - loss: 0.5732 - accuracy: 0.7703\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 132s 7ms/step - loss: 0.5483 - accuracy: 0.7817\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 132s 7ms/step - loss: 0.5328 - accuracy: 0.7891\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 132s 7ms/step - loss: 0.5179 - accuracy: 0.7967\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 132s 7ms/step - loss: 0.5065 - accuracy: 0.8026\n",
      "Evaluation:\n",
      "6586/6586 [==============================] - 15s 2ms/step - loss: 0.6687 - accuracy: 0.7881\n",
      "Max pooling: False\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 194s 10ms/step - loss: 1.1461 - accuracy: 0.5382\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 196s 10ms/step - loss: 0.6530 - accuracy: 0.7301\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 197s 10ms/step - loss: 0.5422 - accuracy: 0.7812\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 202s 10ms/step - loss: 0.4860 - accuracy: 0.8068\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 202s 10ms/step - loss: 0.4474 - accuracy: 0.8246\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 200s 10ms/step - loss: 0.4235 - accuracy: 0.8358\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 197s 10ms/step - loss: 0.4035 - accuracy: 0.8448\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 197s 10ms/step - loss: 0.3895 - accuracy: 0.8514\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 198s 10ms/step - loss: 0.3774 - accuracy: 0.8569\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 201s 10ms/step - loss: 0.3674 - accuracy: 0.8618\n",
      "Evaluation:\n",
      "6586/6586 [==============================] - 17s 3ms/step - loss: 0.9164 - accuracy: 0.7698\n",
      "=====================================================\n",
      "\n",
      "=== Model with 3 convolutional layers ===\n",
      "Max pooling: True\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 134s 7ms/step - loss: 1.2642 - accuracy: 0.4823\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 136s 7ms/step - loss: 0.7839 - accuracy: 0.6681\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 138s 7ms/step - loss: 0.6578 - accuracy: 0.7299\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 138s 7ms/step - loss: 0.5900 - accuracy: 0.7633\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 137s 7ms/step - loss: 0.5456 - accuracy: 0.7843\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 137s 7ms/step - loss: 0.5155 - accuracy: 0.7989\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 135s 7ms/step - loss: 0.4882 - accuracy: 0.8116\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 136s 7ms/step - loss: 0.4710 - accuracy: 0.8197\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 139s 7ms/step - loss: 0.4539 - accuracy: 0.8268\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 140s 7ms/step - loss: 0.4416 - accuracy: 0.8329\n",
      "Evaluation:\n",
      "6586/6586 [==============================] - 16s 2ms/step - loss: 0.6401 - accuracy: 0.7995\n",
      "Max pooling: False\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 205s 10ms/step - loss: 1.0993 - accuracy: 0.5562\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 208s 11ms/step - loss: 0.6105 - accuracy: 0.7528\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 206s 10ms/step - loss: 0.5054 - accuracy: 0.8012\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 205s 10ms/step - loss: 0.4514 - accuracy: 0.8260\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 196s 10ms/step - loss: 0.4210 - accuracy: 0.8399\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 201s 10ms/step - loss: 0.3975 - accuracy: 0.8503\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 195s 10ms/step - loss: 0.3803 - accuracy: 0.8583\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 203s 10ms/step - loss: 0.3680 - accuracy: 0.8633\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 208s 11ms/step - loss: 0.3569 - accuracy: 0.8682\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 207s 11ms/step - loss: 0.3476 - accuracy: 0.8726\n",
      "Evaluation:\n",
      "6586/6586 [==============================] - 18s 3ms/step - loss: 0.6899 - accuracy: 0.8022\n",
      "=====================================================\n",
      "\n",
      "=== Model with 4 convolutional layers ===\n",
      "Max pooling: True\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 144s 7ms/step - loss: 1.1898 - accuracy: 0.5135\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 146s 7ms/step - loss: 0.6826 - accuracy: 0.7211\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 147s 7ms/step - loss: 0.5663 - accuracy: 0.7761\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 157s 8ms/step - loss: 0.5017 - accuracy: 0.8065\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 178s 9ms/step - loss: 0.4593 - accuracy: 0.8259\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 153s 8ms/step - loss: 0.4271 - accuracy: 0.8394\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 159s 8ms/step - loss: 0.4055 - accuracy: 0.8503\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 153s 8ms/step - loss: 0.3887 - accuracy: 0.8582\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 158s 8ms/step - loss: 0.3766 - accuracy: 0.8637\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 160s 8ms/step - loss: 0.3644 - accuracy: 0.8689\n",
      "Evaluation:\n",
      "6586/6586 [==============================] - 17s 3ms/step - loss: 0.5680 - accuracy: 0.8248\n",
      "Max pooling: False\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 212s 11ms/step - loss: 1.0391 - accuracy: 0.5840\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 212s 11ms/step - loss: 0.5583 - accuracy: 0.7796\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 215s 11ms/step - loss: 0.4646 - accuracy: 0.8232\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 211s 11ms/step - loss: 0.4141 - accuracy: 0.8455\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 211s 11ms/step - loss: 0.3847 - accuracy: 0.8582\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 211s 11ms/step - loss: 0.3643 - accuracy: 0.8676\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 213s 11ms/step - loss: 0.3495 - accuracy: 0.8738\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 212s 11ms/step - loss: 0.3395 - accuracy: 0.8781\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 217s 11ms/step - loss: 0.3292 - accuracy: 0.8832\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 212s 11ms/step - loss: 0.3225 - accuracy: 0.8864\n",
      "Evaluation:\n",
      "6586/6586 [==============================] - 20s 3ms/step - loss: 0.6558 - accuracy: 0.8124\n",
      "=====================================================\n",
      "\n",
      "=== Model with 5 convolutional layers ===\n",
      "Max pooling: True\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 160s 8ms/step - loss: 1.1996 - accuracy: 0.5100\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 159s 8ms/step - loss: 0.6618 - accuracy: 0.7334\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 157s 8ms/step - loss: 0.5191 - accuracy: 0.8005\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 157s 8ms/step - loss: 0.4468 - accuracy: 0.8336\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 156s 8ms/step - loss: 0.4080 - accuracy: 0.8518\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 155s 8ms/step - loss: 0.3820 - accuracy: 0.8635\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 153s 8ms/step - loss: 0.3664 - accuracy: 0.8704\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 145s 7ms/step - loss: 0.3529 - accuracy: 0.8766\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 146s 7ms/step - loss: 0.3420 - accuracy: 0.8821\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 143s 7ms/step - loss: 0.3358 - accuracy: 0.8850\n",
      "Evaluation:\n",
      "6586/6586 [==============================] - 18s 3ms/step - loss: 0.6330 - accuracy: 0.8366\n",
      "Max pooling: False\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 198s 10ms/step - loss: 1.0036 - accuracy: 0.6042\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 191s 10ms/step - loss: 0.5165 - accuracy: 0.8026\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 191s 10ms/step - loss: 0.4253 - accuracy: 0.8425\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 191s 10ms/step - loss: 0.3821 - accuracy: 0.8612\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 193s 10ms/step - loss: 0.3553 - accuracy: 0.8736\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 196s 10ms/step - loss: 0.3370 - accuracy: 0.8810\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 198s 10ms/step - loss: 0.3247 - accuracy: 0.8863\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 197s 10ms/step - loss: 0.3142 - accuracy: 0.8906\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 196s 10ms/step - loss: 0.3078 - accuracy: 0.8940\n",
      "Epoch 10/10\n",
      "17841/19643 [==========================>...] - ETA: 17s - loss: 0.3027 - accuracy: 0.8957"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "best_accuracy = 0\n",
    "best_model_specs = None\n",
    "\n",
    "for cnn_layers in range(2, 6):\n",
    "    print(f'=== Model with {cnn_layers} convolutional layers ===')\n",
    "    \n",
    "    for pooling in [True, False]:\n",
    "        print(f\"Max pooling: {pooling}\")\n",
    "        model, _ = create_model(X_train, y_train, X_test, y_test, cnn_layers=cnn_layers, pooling=pooling)\n",
    "        \n",
    "        print('Evaluation:')\n",
    "        loss, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_model_specs = (model, cnn_layers, pooling)\n",
    "            best_accuracy = accuracy\n",
    "\n",
    "    print('=====================================================\\n')\n",
    "    \n",
    "print()\n",
    "print(\"RESULTS:\")\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n",
    "\n",
    "best_model, best_layers, best_pooling = best_model_specs\n",
    "print(f\"CNN layers: {best_layers}\")\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n",
    "print(f\"Best pooling: {best_pooling}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f787e33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 23, 64)            2944      \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 21, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 19, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 17, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 15, 64)            12352     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 15, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1000)              961000    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 360)               360360    \n",
      "=================================================================\n",
      "Total params: 1,373,712\n",
      "Trainable params: 1,373,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7de0f35c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6586/6586 [==============================] - 36s 6ms/step - loss: 0.6799 - accuracy: 0.8418\n",
      "Accuracy: 0.842\n",
      "RMSE: 12.431\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "accuracy = evaluate_model(best_model, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "y_pred_nn = encoder.inverse_transform(best_model.predict(X_test))\n",
    "y_true_nn = encoder.inverse_transform(y_test)\n",
    "print(f'RMSE: {rmse(y_true_nn, y_pred_nn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "630c8f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Room sizes\n",
      "small room accuracy: 0.838\n",
      "medium room accuracy: 0.841\n",
      "large room accuracy: 0.846\n",
      "\n",
      "Distances\n",
      "50 cm distance accuracy: 0.636\n",
      "150 cm distance accuracy: 0.955\n",
      "200 cm distance accuracy: 0.959\n",
      "250 cm distance accuracy: 0.943\n",
      "350 cm distance accuracy: 0.927\n",
      "450 cm distance accuracy: 0.937\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance for different properties\n",
    "print('Room sizes')\n",
    "for room in ROOMS:\n",
    "    _, acc = evaluate_for_property(df_train, df_test, 'room', room)\n",
    "    print(f\"{room} room accuracy: {acc}\")\n",
    "    \n",
    "print('\\nDistances')\n",
    "for dist in np.unique(df_test.dist):\n",
    "    _, acc = evaluate_for_property(df_train, df_test, 'dist', dist)\n",
    "    print(f\"{dist} cm distance accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daec8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(\"../models/best_super_model\")\n",
    "\n",
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the Lite model.\n",
    "with open('../models/best_super_azimuth_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90666a55",
   "metadata": {},
   "source": [
    "### Experiment with CNN-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee5979c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model with 2 convolutional layers and LSTM layer ===\n",
      "Max pooling: True\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 310s 16ms/step - loss: 1.2800 - accuracy: 0.4820\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 307s 16ms/step - loss: 0.7234 - accuracy: 0.6993\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 321s 16ms/step - loss: 0.5884 - accuracy: 0.7615\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 305s 16ms/step - loss: 0.5181 - accuracy: 0.7935\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 306s 16ms/step - loss: 0.4702 - accuracy: 0.8146\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 308s 16ms/step - loss: 0.4329 - accuracy: 0.8304\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 310s 16ms/step - loss: 0.4052 - accuracy: 0.8421\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 310s 16ms/step - loss: 0.3845 - accuracy: 0.8508\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 311s 16ms/step - loss: 0.3658 - accuracy: 0.8587\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 310s 16ms/step - loss: 0.3493 - accuracy: 0.8654\n",
      "Evaluation:\n",
      "6586/6586 [==============================] - 30s 5ms/step - loss: 0.7999 - accuracy: 0.7547\n",
      "Max pooling: False\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 487s 25ms/step - loss: 1.1465 - accuracy: 0.5411\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 484s 25ms/step - loss: 0.5587 - accuracy: 0.7766\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 482s 25ms/step - loss: 0.4254 - accuracy: 0.8351\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 471s 24ms/step - loss: 0.3580 - accuracy: 0.8633\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 461s 23ms/step - loss: 0.3161 - accuracy: 0.8801\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 459s 23ms/step - loss: 0.2847 - accuracy: 0.8929\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 456s 23ms/step - loss: 0.2608 - accuracy: 0.9024\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 458s 23ms/step - loss: 0.2438 - accuracy: 0.9090\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 455s 23ms/step - loss: 0.2296 - accuracy: 0.9143\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 460s 23ms/step - loss: 0.2186 - accuracy: 0.9189\n",
      "Evaluation:\n",
      "6586/6586 [==============================] - 45s 7ms/step - loss: 1.0557 - accuracy: 0.7133\n",
      "=====================================================\n",
      "\n",
      "=== Model with 3 convolutional layers and LSTM layer ===\n",
      "Max pooling: True\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 297s 15ms/step - loss: 1.1739 - accuracy: 0.5330\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 293s 15ms/step - loss: 0.6266 - accuracy: 0.7472\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 286s 15ms/step - loss: 0.5066 - accuracy: 0.8008\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 281s 14ms/step - loss: 0.4424 - accuracy: 0.8287\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 291s 15ms/step - loss: 0.4010 - accuracy: 0.8460\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 287s 15ms/step - loss: 0.3710 - accuracy: 0.8584\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 284s 14ms/step - loss: 0.3484 - accuracy: 0.8682\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 288s 15ms/step - loss: 0.3308 - accuracy: 0.8752\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 279s 14ms/step - loss: 0.3156 - accuracy: 0.8814\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 280s 14ms/step - loss: 0.3026 - accuracy: 0.8865\n",
      "Evaluation:\n",
      "6586/6586 [==============================] - 29s 4ms/step - loss: 0.7740 - accuracy: 0.7930\n",
      "Max pooling: False\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 442s 22ms/step - loss: 1.0961 - accuracy: 0.5665\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 464s 24ms/step - loss: 0.5177 - accuracy: 0.7962\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 459s 23ms/step - loss: 0.3983 - accuracy: 0.8481\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 469s 24ms/step - loss: 0.3350 - accuracy: 0.8744\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 466s 24ms/step - loss: 0.2952 - accuracy: 0.8906\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 468s 24ms/step - loss: 0.2689 - accuracy: 0.9013\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 489s 25ms/step - loss: 0.2488 - accuracy: 0.9088\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 491s 25ms/step - loss: 0.2320 - accuracy: 0.9154\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 478s 24ms/step - loss: 0.2204 - accuracy: 0.9199\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 471s 24ms/step - loss: 0.2113 - accuracy: 0.9232\n",
      "Evaluation:\n",
      "6586/6586 [==============================] - 46s 7ms/step - loss: 0.8162 - accuracy: 0.7787\n",
      "=====================================================\n",
      "\n",
      "=== Model with 4 convolutional layers and LSTM layer ===\n",
      "Max pooling: True\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 321s 16ms/step - loss: 1.1460 - accuracy: 0.5511\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 316s 16ms/step - loss: 0.5910 - accuracy: 0.7654\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 322s 16ms/step - loss: 0.4759 - accuracy: 0.8166\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 301s 15ms/step - loss: 0.4167 - accuracy: 0.8427\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 300s 15ms/step - loss: 0.3792 - accuracy: 0.8583\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 297s 15ms/step - loss: 0.3511 - accuracy: 0.8706\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 300s 15ms/step - loss: 0.3357 - accuracy: 0.8773\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 296s 15ms/step - loss: 0.3209 - accuracy: 0.8832\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 296s 15ms/step - loss: 0.3104 - accuracy: 0.8876\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 294s 15ms/step - loss: 0.3027 - accuracy: 0.8911\n",
      "Evaluation:\n",
      "6586/6586 [==============================] - 34s 5ms/step - loss: 0.9015 - accuracy: 0.7815\n",
      "Max pooling: False\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 447s 23ms/step - loss: 1.0383 - accuracy: 0.5934\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 449s 23ms/step - loss: 0.4676 - accuracy: 0.8210\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 447s 23ms/step - loss: 0.3633 - accuracy: 0.8655\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 477s 24ms/step - loss: 0.3133 - accuracy: 0.8854\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 504s 26ms/step - loss: 0.2825 - accuracy: 0.8981\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 499s 25ms/step - loss: 0.2619 - accuracy: 0.9060\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 486s 25ms/step - loss: 0.2463 - accuracy: 0.9123\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 485s 25ms/step - loss: 0.2335 - accuracy: 0.9167\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 485s 25ms/step - loss: 0.2247 - accuracy: 0.9203\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 484s 25ms/step - loss: 0.2174 - accuracy: 0.9231\n",
      "Evaluation:\n",
      "6586/6586 [==============================] - 102s 15ms/step - loss: 0.8760 - accuracy: 0.8087\n",
      "=====================================================\n",
      "\n",
      "=== Model with 5 convolutional layers and LSTM layer ===\n",
      "Max pooling: True\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 296s 15ms/step - loss: 1.2643 - accuracy: 0.4991\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 298s 15ms/step - loss: 0.6421 - accuracy: 0.7442\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 299s 15ms/step - loss: 0.4954 - accuracy: 0.8112\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 299s 15ms/step - loss: 0.4285 - accuracy: 0.8403\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 300s 15ms/step - loss: 0.3860 - accuracy: 0.8580\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 299s 15ms/step - loss: 0.3570 - accuracy: 0.8703\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 299s 15ms/step - loss: 0.3357 - accuracy: 0.8794\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 299s 15ms/step - loss: 0.3217 - accuracy: 0.8850\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 307s 16ms/step - loss: 0.3077 - accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 309s 16ms/step - loss: 0.3005 - accuracy: 0.8940\n",
      "Evaluation:\n",
      "6586/6586 [==============================] - 63s 9ms/step - loss: 0.7780 - accuracy: 0.7952\n",
      "Max pooling: False\n",
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 30727s 2s/step - loss: 1.0283 - accuracy: 0.6075\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 426s 22ms/step - loss: 0.4593 - accuracy: 0.8270\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 419s 21ms/step - loss: 0.3601 - accuracy: 0.8692\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 416s 21ms/step - loss: 0.3123 - accuracy: 0.8883\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 424s 22ms/step - loss: 0.2825 - accuracy: 0.9001\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 422s 21ms/step - loss: 0.2642 - accuracy: 0.9078\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 427s 22ms/step - loss: 0.2528 - accuracy: 0.9121\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 421s 21ms/step - loss: 0.2419 - accuracy: 0.9160\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 434s 22ms/step - loss: 0.2357 - accuracy: 0.9192\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 441s 22ms/step - loss: 0.2307 - accuracy: 0.9207\n",
      "Evaluation:\n",
      "6586/6586 [==============================] - 47s 7ms/step - loss: 0.6333 - accuracy: 0.8215\n",
      "=====================================================\n",
      "\n",
      "\n",
      "RESULTS:\n",
      "Best accuracy: 0.8214909434318542\n",
      "CNN layers: 5\n",
      "Best pooling: False\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "best_lstm_accuracy = 0\n",
    "best_lstm_model_specs = None\n",
    "\n",
    "for cnn_layers in range(2, 6):\n",
    "    print(f'=== Model with {cnn_layers} convolutional layers and LSTM layer ===')\n",
    "    \n",
    "    for pooling in [True, False]:\n",
    "        print(f\"Max pooling: {pooling}\")\n",
    "        model, _ = create_model(X_train, y_train, X_test, y_test, cnn_layers=cnn_layers, pooling=pooling, lstm=True)\n",
    "        \n",
    "        print('Evaluation:')\n",
    "        loss, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "        if accuracy > best_lstm_accuracy:\n",
    "            best_lstm_model_specs = (model, cnn_layers, pooling)\n",
    "            best_lstm_accuracy = accuracy\n",
    "\n",
    "    print('=====================================================\\n')\n",
    "    \n",
    "print()\n",
    "print(\"RESULTS:\")\n",
    "print(f\"Best accuracy: {best_lstm_accuracy}\")\n",
    "\n",
    "best_lstm_model, best_lstm_layers, best_lstm_pooling = best_lstm_model_specs\n",
    "print(f\"CNN layers: {best_lstm_layers}\")\n",
    "print(f\"Best pooling: {best_lstm_pooling}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "162c8a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 23, 64)            2944      \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 21, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 19, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 17, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 15, 64)            12352     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 15, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 15, 128)           98816     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1000)              1921000   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 360)               360360    \n",
      "=================================================================\n",
      "Total params: 2,432,528\n",
      "Trainable params: 2,432,528\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75db4a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6586/6586 [==============================] - 46s 7ms/step - loss: 0.6333 - accuracy: 0.8215\n",
      "Accuracy: 0.821\n",
      "RMSE: 10.83\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "accuracy = evaluate_model(best_lstm_model, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "y_pred_nn = encoder.inverse_transform(best_lstm_model.predict(X_test))\n",
    "y_true_nn = encoder.inverse_transform(y_test)\n",
    "print(f'RMSE: {rmse(y_true_nn, y_pred_nn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "139100ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Room sizes\n",
      "small room accuracy: 0.819\n",
      "medium room accuracy: 0.818\n",
      "large room accuracy: 0.827\n",
      "\n",
      "Distances\n",
      "50 cm distance accuracy: 0.589\n",
      "150 cm distance accuracy: 0.941\n",
      "200 cm distance accuracy: 0.949\n",
      "250 cm distance accuracy: 0.94\n",
      "350 cm distance accuracy: 0.92\n",
      "450 cm distance accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance for different properties\n",
    "print('Room sizes')\n",
    "for room in ROOMS:\n",
    "    _, acc = evaluate_for_property(df_train, df_test, 'room', room)\n",
    "    print(f\"{room} room accuracy: {acc}\")\n",
    "    \n",
    "print('\\nDistances')\n",
    "for dist in np.unique(df_test.dist):\n",
    "    _, acc = evaluate_for_property(df_train, df_test, 'dist', dist)\n",
    "    print(f\"{dist} cm distance accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e6da477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/best_lstm_super_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/best_lstm_super_model\\assets\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tkhor\\AppData\\Local\\Temp\\tmp6al03d2m\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tkhor\\AppData\\Local\\Temp\\tmp6al03d2m\\assets\n"
     ]
    }
   ],
   "source": [
    "best_lstm_model.save(\"../models/best_lstm_super_model\")\n",
    "\n",
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(best_lstm_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the Lite model.\n",
    "with open('../models/best_lstm_super_azimuth_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92237590",
   "metadata": {},
   "source": [
    "### Compare to MUSIC baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "753fbce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 3240/3240\n",
      "Accuracy: 0.29\n",
      "RMSE: 2.183\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred, info = get_all_predictions(True, samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "print()\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy: {round(accuracy, 3)}')\n",
    "print(f'RMSE: {rmse(y_true, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8557e14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Room sizes\n",
      "small room accuracy: 0.232\n",
      "medium room accuracy: 0.279\n",
      "large room accuracy: 0.359\n",
      "\n",
      "Distances\n",
      "150 cm distance accuracy: 0.158\n",
      "200 cm distance accuracy: 0.27\n",
      "250 cm distance accuracy: 0.246\n",
      "350 cm distance accuracy: 0.224\n",
      "450 cm distance accuracy: 0.291\n",
      "50 cm distance accuracy: 0.394\n"
     ]
    }
   ],
   "source": [
    "def get_entries_with_property(info, prop, value):\n",
    "    if prop == 'distance': i = 0\n",
    "    elif prop == 'room': i = 1\n",
    "        \n",
    "    info = info[:, i]\n",
    "    return np.where(info == value)\n",
    "\n",
    "# Evaluate performance for different properties\n",
    "print('Room sizes')\n",
    "for room in ROOMS:\n",
    "    indices = get_entries_with_property(info, 'room', room)\n",
    "    y_true_room, y_pred_room = np.take(y_true, indices)[0], np.take(y_pred, indices)[0]\n",
    "    accuracy = accuracy_score(y_true_room, y_pred_room)\n",
    "    print(f\"{room} room accuracy: {round(accuracy, 3)}\")\n",
    "    \n",
    "print('\\nDistances')\n",
    "for dist in np.unique(info[:, 0]):\n",
    "    indices = get_entries_with_property(info, 'distance', dist)\n",
    "    y_true_dist, y_pred_dist = np.take(y_true, indices)[0], np.take(y_pred, indices)[0]\n",
    "    accuracy = accuracy_score(y_true_dist, y_pred_dist)\n",
    "    print(f\"{dist} cm distance accuracy: {round(accuracy, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce3957b",
   "metadata": {},
   "source": [
    "### Model quantization for TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f3fc4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "quantize_model = tfmot.quantization.keras.quantize_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61a2d0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((628560, 25, 15, 1), (210740, 25, 15, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_quant = X_train[..., np.newaxis]\n",
    "X_test_quant = X_test[..., np.newaxis]\n",
    "X_train_quant.shape, X_test_quant.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cffcfa9",
   "metadata": {},
   "source": [
    "Verify if features are created correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e2e03ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train_quant[30][:, :, 0], aspect=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26b9048",
   "metadata": {},
   "source": [
    "#### Create a standard Conv2D model - for compatiblility with TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "778faba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if the model is already saved\n",
    "model = load_model(\"../models/quant_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e095ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, batch_size, verbose = 10, 32, 1\n",
    "n_timesteps, n_features, n_outputs = X_train_quant.shape[1], X_train_quant.shape[2], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef6edcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, n_features), activation='relu', input_shape=(n_timesteps, n_features, 1)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 1), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 1), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 1), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdff3a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 23, 1, 64)         2944      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 21, 1, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 19, 1, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 17, 1, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 15, 1, 64)         12352     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 1, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              961000    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 360)               360360    \n",
      "=================================================================\n",
      "Total params: 1,373,712\n",
      "Trainable params: 1,373,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c224aa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19643/19643 [==============================] - 118s 6ms/step - loss: 1.0695 - accuracy: 0.5833\n",
      "Epoch 2/10\n",
      "19643/19643 [==============================] - 111s 6ms/step - loss: 0.5493 - accuracy: 0.7876\n",
      "Epoch 3/10\n",
      "19643/19643 [==============================] - 111s 6ms/step - loss: 0.4506 - accuracy: 0.8320\n",
      "Epoch 4/10\n",
      "19643/19643 [==============================] - 111s 6ms/step - loss: 0.4048 - accuracy: 0.8520\n",
      "Epoch 5/10\n",
      "19643/19643 [==============================] - 111s 6ms/step - loss: 0.3764 - accuracy: 0.8644\n",
      "Epoch 6/10\n",
      "19643/19643 [==============================] - 110s 6ms/step - loss: 0.3594 - accuracy: 0.8717\n",
      "Epoch 7/10\n",
      "19643/19643 [==============================] - 111s 6ms/step - loss: 0.3431 - accuracy: 0.8792\n",
      "Epoch 8/10\n",
      "19643/19643 [==============================] - 112s 6ms/step - loss: 0.3340 - accuracy: 0.8834\n",
      "Epoch 9/10\n",
      "19643/19643 [==============================] - 111s 6ms/step - loss: 0.3245 - accuracy: 0.8873\n",
      "Epoch 10/10\n",
      "19643/19643 [==============================] - 110s 6ms/step - loss: 0.3182 - accuracy: 0.8903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1adebb45610>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(X_train_quant, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d222a0",
   "metadata": {},
   "source": [
    "#### Evaluate the standard (non-quantized) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a3c625b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6586/6586 [==============================] - 22s 3ms/step - loss: 0.5715 - accuracy: 0.8341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5714851021766663, 0.8340941667556763]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_quant, y_test, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77fda798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/quant_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../models/quant_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc9739",
   "metadata": {},
   "source": [
    "#### Retrain the model with quantization aware training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b47a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "quantize_layer (QuantizeLaye (None, 25, 15, 1)         3         \n",
      "_________________________________________________________________\n",
      "quant_conv2d_5 (QuantizeWrap (None, 23, 1, 64)         3075      \n",
      "_________________________________________________________________\n",
      "quant_conv2d_6 (QuantizeWrap (None, 21, 1, 64)         12483     \n",
      "_________________________________________________________________\n",
      "quant_conv2d_7 (QuantizeWrap (None, 19, 1, 64)         12483     \n",
      "_________________________________________________________________\n",
      "quant_conv2d_8 (QuantizeWrap (None, 17, 1, 64)         12483     \n",
      "_________________________________________________________________\n",
      "quant_conv2d_9 (QuantizeWrap (None, 15, 1, 64)         12483     \n",
      "_________________________________________________________________\n",
      "quant_dropout_1 (QuantizeWra (None, 15, 1, 64)         1         \n",
      "_________________________________________________________________\n",
      "quant_flatten_1 (QuantizeWra (None, 960)               1         \n",
      "_________________________________________________________________\n",
      "quant_dense_2 (QuantizeWrapp (None, 1000)              961005    \n",
      "_________________________________________________________________\n",
      "quant_dense_3 (QuantizeWrapp (None, 360)               360365    \n",
      "=================================================================\n",
      "Total params: 1,374,382\n",
      "Trainable params: 1,373,712\n",
      "Non-trainable params: 670\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "q_aware_model = quantize_model(model)\n",
    "q_aware_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "625c3f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19643/19643 [==============================] - 442s 22ms/step - loss: 0.3350 - accuracy: 0.8832\n"
     ]
    }
   ],
   "source": [
    "history = q_aware_model.fit(X_train_quant, y_train, epochs=1, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2ecf23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_5_layer_call_and_return_conditional_losses, conv2d_5_layer_call_fn, conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/q_aware_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/q_aware_model\\assets\n"
     ]
    }
   ],
   "source": [
    "q_aware_model.save(\"../models/q_aware_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb29e51b",
   "metadata": {},
   "source": [
    "#### Evaluate the quantization-aware model (still not actually quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45381567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6586/6586 [==============================] - 51s 8ms/step - loss: 0.7179 - accuracy: 0.8304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7178905010223389, 0.8304119110107422]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_aware_model.evaluate(X_test_quant, y_test, batch_size=batch_size, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035324ab",
   "metadata": {},
   "source": [
    "#### Quantize the model and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeff5f2",
   "metadata": {},
   "source": [
    "Helper function to call TFLite model on test samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7114902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(interpeter):\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "    \n",
    "    input_index = input_details[\"index\"]\n",
    "    output_index = output_details[\"index\"]\n",
    "    \n",
    "    predictions = []\n",
    "    samples = X_test_quant[::100] \n",
    "    \n",
    "    for i, obs in enumerate(samples):\n",
    "        print(f'Sample {i + 1}/{len(samples)}', end='\\r')\n",
    "        \n",
    "        if input_details['dtype'] == np.uint8:\n",
    "            input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "            obs = obs / input_scale + input_zero_point\n",
    "            \n",
    "        interpreter.set_tensor(input_index, [obs.astype(input_details[\"dtype\"])])\n",
    "        interpreter.invoke()\n",
    "        \n",
    "        output = interpreter.get_tensor(output_index)\n",
    "        angle = np.argmax(output[0]) * RESOLUTION\n",
    "        \n",
    "        predictions.append(angle)\n",
    "        \n",
    "    print()\n",
    "        \n",
    "    predictions = np.array(predictions)\n",
    "    accuracy = (predictions == df_test.label.values[::100]).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3319e3e1",
   "metadata": {},
   "source": [
    "1) Quantization-aware model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2811ca6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_5_layer_call_and_return_conditional_losses, conv2d_5_layer_call_fn, conv2d_6_layer_call_and_return_conditional_losses, conv2d_6_layer_call_fn, conv2d_7_layer_call_and_return_conditional_losses while saving (showing 5 of 45). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tkhor\\AppData\\Local\\Temp\\tmpnjm9bdxb\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tkhor\\AppData\\Local\\Temp\\tmpnjm9bdxb\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "# Save the Lite model.\n",
    "with open('../models/quant_azimuth_model.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3959034f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2108/2108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8325426944971537"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ebde9",
   "metadata": {},
   "source": [
    "2) Quantization-non-aware model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b33d62f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tkhor\\AppData\\Local\\Temp\\tmpckb0kmr0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tkhor\\AppData\\Local\\Temp\\tmpckb0kmr0\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "non_aware_tflite_model = converter.convert()\n",
    "\n",
    "# Save the Lite model.\n",
    "with open('../models/non_aware_model.tflite', 'wb') as f:\n",
    "    f.write(non_aware_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f12057a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2108/2108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.829696394686907"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=non_aware_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c7937e",
   "metadata": {},
   "source": [
    "3) Non-quantized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04d496a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tkhor\\AppData\\Local\\Temp\\tmpfqlzp1oq\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tkhor\\AppData\\Local\\Temp\\tmpfqlzp1oq\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "# Save the Lite model.\n",
    "with open('../models/conv_2d_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc37572d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2108/2108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8282732447817837"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd070df",
   "metadata": {},
   "source": [
    "#### Quantize inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f882836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(X_train_quant.astype(np.float32)).batch(1).take(100):\n",
    "        yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0d442ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tkhor\\AppData\\Local\\Temp\\tmpxr_phx5v\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tkhor\\AppData\\Local\\Temp\\tmpxr_phx5v\\assets\n",
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cca4d207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2108/2108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8273244781783681"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "interpreter.allocate_tensors()\n",
    "test_accuracy = evaluate_model(interpreter)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b15a33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'conv2d_5_input',\n",
       "  'index': 0,\n",
       "  'shape': array([ 1, 25, 15,  1]),\n",
       "  'shape_signature': array([-1, 25, 15,  1]),\n",
       "  'dtype': numpy.uint8,\n",
       "  'quantization': (0.002377354074269533, 45),\n",
       "  'quantization_parameters': {'scales': array([0.00237735], dtype=float32),\n",
       "   'zero_points': array([45]),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_input_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85267059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Lite model.\n",
    "with open('../models/quant_input_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
