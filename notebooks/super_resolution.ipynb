{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22976b0e",
   "metadata": {},
   "source": [
    "# CNN DOA with 1 degree resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec58991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "from training import rmse\n",
    "from music import get_all_predictions\n",
    "from training import create_model, evaluate_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from pyroomacoustics.transform import stft\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85ecb62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label resolution of classification\n",
    "RESOLUTION = 1\n",
    "\n",
    "# Number of samples to include while creating one ML feature\n",
    "SAMPLES = 4096\n",
    "\n",
    "# Determines the overlap of samples between consecutive features\n",
    "STEP = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff00a40d",
   "metadata": {},
   "source": [
    "### Create training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "358a241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train file 3240/3240\n",
      "test file 3240/3240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tkhor\\AppData\\Local\\Temp/ipykernel_16868/482052796.py:70: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train = df_train.drop(['dist', 'room', 'label'], 1).values.reshape(\n",
      "C:\\Users\\tkhor\\AppData\\Local\\Temp/ipykernel_16868/482052796.py:72: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test = df_test.drop(['dist', 'room', 'label'], 1).values.reshape(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((628560, 15, 25), (210740, 15, 25), (628560, 360), (210740, 360))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_dataframe('train', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "print()\n",
    "df_test = create_dataframe('test', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "print()\n",
    "\n",
    "df_train.to_csv('../training_data/super_azimuth_train_dataset.csv')\n",
    "df_test.to_csv('../training_data/super_azimuth_test_dataset.csv')\n",
    "\n",
    "# Create numpy arrays with observations and one-hot labels\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "X_train, y_train, X_test, y_test = create_whole_dataset(df_train, df_test, encoder)\n",
    "\n",
    "np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ddba82",
   "metadata": {},
   "source": [
    "Only run this when all the variables are not stored in memory (i.e. after restarting the kernel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eae0e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((628560, 15, 13), (210740, 15, 13), (628560, 360), (210740, 360))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../training_data/super_azimuth_train_dataset.csv', index_col=[0])\n",
    "df_test = pd.read_csv('../training_data/super_azimuth_test_dataset.csv', index_col=[0])\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "encoder.fit([[label] for label in df_train['label']])\n",
    "X_train, y_train, X_test, y_test = create_whole_dataset(df_train, df_test, encoder)\n",
    "np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3755ab",
   "metadata": {},
   "source": [
    "### Fit and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df8586fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((628560, 25, 15), (210740, 25, 15))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose the observations because Conv1D requires timesteps as the 1st dim\n",
    "if X_train.shape[1] == MIC_COMBS:\n",
    "    X_train, X_test = np.transpose(X_train, axes=[0, 2, 1]), np.transpose(X_test, axes=[0, 2, 1])\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47903943",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, batch_size, verbose = 20, 32, 1\n",
    "\n",
    "# Fit model\n",
    "def create_model(X_train, y_train, X_test, y_test):\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "\n",
    "    # Init model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add layers\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ceca0079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_22 (Conv1D)           (None, 23, 64)            2944      \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 21, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 19, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 17, 64)            12352     \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 15, 64)            12352     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 15, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1000)              449000    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 360)               360360    \n",
      "=================================================================\n",
      "Total params: 861,712\n",
      "Trainable params: 861,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add layers\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(25,15)))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(360, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = create_model(X_train, y_train, X_test, y_test)\n",
    "np.save('../models/super_history.npy', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eeb9925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6586/6586 [==============================] - 8s 1ms/step - loss: 0.9844 - accuracy: 0.7454\n",
      "Accuracy: 0.745\n",
      "RMSE: 29.946\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "accuracy = evaluate_model(model, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "y_pred_nn = encoder.inverse_transform(model.predict(X_test))\n",
    "y_true_nn = encoder.inverse_transform(y_test)\n",
    "print(f'RMSE: {rmse(y_true_nn, y_pred_nn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f84721d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Room sizes\n",
      "small room accuracy: 0.74\n",
      "medium room accuracy: 0.743\n",
      "large room accuracy: 0.753\n",
      "\n",
      "Distances\n",
      "50 cm distance accuracy: 0.419\n",
      "150 cm distance accuracy: 0.919\n",
      "200 cm distance accuracy: 0.927\n",
      "250 cm distance accuracy: 0.908\n",
      "350 cm distance accuracy: 0.886\n",
      "450 cm distance accuracy: 0.895\n"
     ]
    }
   ],
   "source": [
    "def evaluate_for_property(df_train, df_test, prop, value):\n",
    "    \"\"\"\n",
    "    Measures the model prediction for test samples\n",
    "    with a given property, such as room size.\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    \n",
    "    # Filter test set by property value\n",
    "    X_trn, y_trn, X_tst, y_tst = create_whole_dataset(\n",
    "        df_train, df_test[df_test[prop]==value], encoder\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on the filtered set\n",
    "    X_tst = np.transpose(X_tst, axes=[0, 2, 1])\n",
    "    loss, acc = model.evaluate(X_tst, y_tst, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    return round(loss, 3), round(acc, 3)\n",
    "\n",
    "\n",
    "# Evaluate performance for different properties\n",
    "print('Room sizes')\n",
    "for room in ROOMS:\n",
    "    _, acc = evaluate_for_property(df_train, df_test, 'room', room)\n",
    "    print(f\"{room} room accuracy: {acc}\")\n",
    "    \n",
    "print('\\nDistances')\n",
    "for dist in np.unique(df_test.dist):\n",
    "    _, acc = evaluate_for_property(df_train, df_test, 'dist', dist)\n",
    "    print(f\"{dist} cm distance accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1efcce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/super_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../models/super_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92237590",
   "metadata": {},
   "source": [
    "### Compare to MUSIC baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "753fbce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 3240/3240\n",
      "Accuracy: 0.29\n",
      "RMSE: 2.183\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred, info = get_all_predictions(True, samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "print()\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy: {round(accuracy, 3)}')\n",
    "print(f'RMSE: {rmse(y_true, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8557e14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Room sizes\n",
      "small room accuracy: 0.232\n",
      "medium room accuracy: 0.279\n",
      "large room accuracy: 0.359\n",
      "\n",
      "Distances\n",
      "150 cm distance accuracy: 0.158\n",
      "200 cm distance accuracy: 0.27\n",
      "250 cm distance accuracy: 0.246\n",
      "350 cm distance accuracy: 0.224\n",
      "450 cm distance accuracy: 0.291\n",
      "50 cm distance accuracy: 0.394\n"
     ]
    }
   ],
   "source": [
    "def get_entries_with_property(info, prop, value):\n",
    "    if prop == 'distance': i = 0\n",
    "    elif prop == 'room': i = 1\n",
    "        \n",
    "    info = info[:, i]\n",
    "    return np.where(info == value)\n",
    "\n",
    "# Evaluate performance for different properties\n",
    "print('Room sizes')\n",
    "for room in ROOMS:\n",
    "    indices = get_entries_with_property(info, 'room', room)\n",
    "    y_true_room, y_pred_room = np.take(y_true, indices)[0], np.take(y_pred, indices)[0]\n",
    "    accuracy = accuracy_score(y_true_room, y_pred_room)\n",
    "    print(f\"{room} room accuracy: {round(accuracy, 3)}\")\n",
    "    \n",
    "print('\\nDistances')\n",
    "for dist in np.unique(info[:, 0]):\n",
    "    indices = get_entries_with_property(info, 'distance', dist)\n",
    "    y_true_dist, y_pred_dist = np.take(y_true, indices)[0], np.take(y_pred, indices)[0]\n",
    "    accuracy = accuracy_score(y_true_dist, y_pred_dist)\n",
    "    print(f\"{dist} cm distance accuracy: {round(accuracy, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
