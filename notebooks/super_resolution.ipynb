{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "441014d5",
   "metadata": {},
   "source": [
    "# CNN DOA with 1 degree resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8437a139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "from training import rmse\n",
    "from music import get_all_predictions\n",
    "from training import create_model, evaluate_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9dfe0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label resolution of classification\n",
    "RESOLUTION = 1\n",
    "\n",
    "# Number of samples to include while creating one ML feature\n",
    "SAMPLES = 2048\n",
    "\n",
    "# Determines the overlap of samples between consecutive features\n",
    "STEP = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a03b4",
   "metadata": {},
   "source": [
    "### Create training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cb045ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train file 3240/3240\n",
      "test file 3240/3240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((628560, 15, 13), (210740, 15, 13), (628560, 360), (210740, 360))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_dataframe('train', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "print()\n",
    "df_test = create_dataframe('test', samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "print()\n",
    "\n",
    "df_train.to_csv('../training_data/super_azimuth_train_dataset.csv')\n",
    "df_test.to_csv('../training_data/super_azimuth_test_dataset.csv')\n",
    "\n",
    "# Create numpy arrays with observations and one-hot labels\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "X_train, y_train, X_test, y_test = create_whole_dataset(df_train, df_test, encoder)\n",
    "\n",
    "np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05c0ea9",
   "metadata": {},
   "source": [
    "Only run this when all the variables are not stored in memory (i.e. after restarting the kernel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5187f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((628560, 15, 13), (210740, 15, 13), (628560, 360), (210740, 360))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../training_data/super_azimuth_train_dataset.csv', index_col=[0])\n",
    "df_test = pd.read_csv('../training_data/super_azimuth_test_dataset.csv', index_col=[0])\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "encoder.fit([[label] for label in df_train['label']])\n",
    "X_train, y_train, X_test, y_test = create_whole_dataset(df_train, df_test, encoder)\n",
    "np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b912459",
   "metadata": {},
   "source": [
    "### Fit and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb39f651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((628560, 13, 15), (210740, 13, 15))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose the observations because Conv1D requires timesteps as the 1st dim\n",
    "if X_train.shape[1] == MIC_COMBS:\n",
    "    X_train, X_test = np.transpose(X_train, axes=[0, 2, 1]), np.transpose(X_test, axes=[0, 2, 1])\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c20b5b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19643/19643 [==============================] - 37s 2ms/step - loss: 1.7534 - accuracy: 0.3251\n",
      "Epoch 2/20\n",
      "19643/19643 [==============================] - 39s 2ms/step - loss: 1.1606 - accuracy: 0.4982\n",
      "Epoch 3/20\n",
      "19643/19643 [==============================] - 40s 2ms/step - loss: 1.0253 - accuracy: 0.5605\n",
      "Epoch 4/20\n",
      "19643/19643 [==============================] - 42s 2ms/step - loss: 0.9566 - accuracy: 0.5959\n",
      "Epoch 5/20\n",
      "19643/19643 [==============================] - 42s 2ms/step - loss: 0.9129 - accuracy: 0.6187\n",
      "Epoch 6/20\n",
      "19643/19643 [==============================] - 43s 2ms/step - loss: 0.8816 - accuracy: 0.6344\n",
      "Epoch 7/20\n",
      "19643/19643 [==============================] - 44s 2ms/step - loss: 0.8610 - accuracy: 0.6449\n",
      "Epoch 8/20\n",
      "19643/19643 [==============================] - 43s 2ms/step - loss: 0.8406 - accuracy: 0.6556\n",
      "Epoch 9/20\n",
      "19643/19643 [==============================] - 44s 2ms/step - loss: 0.8266 - accuracy: 0.6627\n",
      "Epoch 10/20\n",
      "19643/19643 [==============================] - 45s 2ms/step - loss: 0.8173 - accuracy: 0.6683\n",
      "Epoch 11/20\n",
      "19643/19643 [==============================] - 45s 2ms/step - loss: 0.8083 - accuracy: 0.6726\n",
      "Epoch 12/20\n",
      "19643/19643 [==============================] - 44s 2ms/step - loss: 0.8006 - accuracy: 0.6770\n",
      "Epoch 13/20\n",
      "19643/19643 [==============================] - 45s 2ms/step - loss: 0.7926 - accuracy: 0.6815\n",
      "Epoch 14/20\n",
      "19643/19643 [==============================] - 46s 2ms/step - loss: 0.7868 - accuracy: 0.6846\n",
      "Epoch 15/20\n",
      "19643/19643 [==============================] - 45s 2ms/step - loss: 0.7808 - accuracy: 0.6879\n",
      "Epoch 16/20\n",
      "19643/19643 [==============================] - 45s 2ms/step - loss: 0.7770 - accuracy: 0.6891\n",
      "Epoch 17/20\n",
      "19643/19643 [==============================] - 45s 2ms/step - loss: 0.7734 - accuracy: 0.6919\n",
      "Epoch 18/20\n",
      "19643/19643 [==============================] - 45s 2ms/step - loss: 0.7711 - accuracy: 0.6939\n",
      "Epoch 19/20\n",
      "19643/19643 [==============================] - 46s 2ms/step - loss: 0.7682 - accuracy: 0.6950\n",
      "Epoch 20/20\n",
      "19643/19643 [==============================] - 46s 2ms/step - loss: 0.7634 - accuracy: 0.6977\n"
     ]
    }
   ],
   "source": [
    "model, history = create_model(X_train, y_train, X_test, y_test)\n",
    "np.save('../models/super_history.npy', history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5909370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6586/6586 [==============================] - 7s 1ms/step - loss: 1.0714 - accuracy: 0.7418\n",
      "Accuracy: 0.742\n",
      "RMSE: 27.711\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "accuracy = evaluate_model(model, X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "y_pred_nn = encoder.inverse_transform(model.predict(X_test))\n",
    "y_true_nn = encoder.inverse_transform(y_test)\n",
    "print(f'RMSE: {rmse(y_true_nn, y_pred_nn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c99a39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/super_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../models/super_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89909a1",
   "metadata": {},
   "source": [
    "### Compare to MUSIC baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03251bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 3240/3240\n",
      "Accuracy: 0.29\n",
      "RMSE: 2.183\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred, _ = get_all_predictions(True, samples=SAMPLES, step=STEP, resolution=RESOLUTION)\n",
    "print()\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy: {round(accuracy, 3)}')\n",
    "print(f'RMSE: {rmse(y_true, y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
