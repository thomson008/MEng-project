{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250e51dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import math\n",
    "import pyroomacoustics as pra\n",
    "from pyroomacoustics.utilities import normalize\n",
    "from pyroomacoustics.transform import stft\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.models import load_model\n",
    "\n",
    "register_matplotlib_converters()\n",
    "sns.set(style='dark', palette='muted', font_scale=1)\n",
    "rcParams['figure.figsize'] = 22, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0805181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label resolution of classification\n",
    "RESOLUTION = 10\n",
    "\n",
    "# Number of samples to include while creating one ML feature\n",
    "SAMPLES = 256\n",
    "\n",
    "# Determines the overlap of samples between consecutive features\n",
    "STEP = 8192\n",
    "\n",
    "# Training rooms dimensions\n",
    "ROOMS = {\n",
    "    'small' : np.array([4, 4, 3]),\n",
    "    'medium' : np.array([6, 6, 3]),\n",
    "    'large' : np.array([8, 8, 3])\n",
    "}\n",
    "\n",
    "# Testing rooms dimensions\n",
    "TEST_ROOMS = {\n",
    "    'small' : np.array([5, 5, 2]),\n",
    "    'medium' : np.array([7, 7, 2]),\n",
    "    'large' : np.array([9, 9, 2])\n",
    "}\n",
    "\n",
    "AUDIO_PATH = '../training_data/audio/multi_source'\n",
    "\n",
    "# Number of microphones on the array\n",
    "MICS_NUMBER = 6\n",
    "\n",
    "MIC_COMBS = len(list(combinations(range(MICS_NUMBER), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9231ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_hot_encode(encoder, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Creates a multi-hot encoding of categorical labels\n",
    "    provided in y_train and y_test.\n",
    "    \"\"\"\n",
    "    \n",
    "    # One-hot encode training and testing labels\n",
    "    enc = encoder.fit(y_train)\n",
    "    y_train = enc.transform(y_train)\n",
    "    y_test = enc.transform(y_test)\n",
    "    \n",
    "    return y_train, y_test\n",
    "  \n",
    "    \n",
    "def create_whole_dataset(df_train, df_test, encoder, room=None, dist=None):\n",
    "    \"\"\"\n",
    "    Creates an entire dataset by extracting values\n",
    "    from train and tests dataframes.\n",
    "    \n",
    "    One-hot encodes the labels before returning.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Can filter testing entries to only check performance\n",
    "    # for given conditions\n",
    "    if room:\n",
    "        df_test = df_test[df_test.room == room]\n",
    "    \n",
    "    # Create train/test observations\n",
    "    X_train = df_train.drop(columns=['room', 'label']).values\n",
    "    X_test = df_test.drop(columns=['room', 'label']).values\n",
    "    \n",
    "    # Create train/test labels\n",
    "    y_train, y_test = multi_hot_encode(\n",
    "        encoder, df_train['label'].values, df_test['label'].values)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def create_observations(wav_signals, label, samples=1, step=1, resolution=20):\n",
    "    # Lists of observations and labels that will be populated\n",
    "    X = tf.signal.frame(wav_signals.T, frame_length=samples, frame_step=step)\n",
    "    return np.transpose(X, axes=[1, 0, 2])\n",
    "\n",
    "\n",
    "def create_dataframe(subset, samples=20, step=5, resolution=20, is_info=True, interp=1):\n",
    "    \"\"\"\n",
    "    Creates a whole dataframe \n",
    "    It is achieved by looping through all WAV files in the directory\n",
    "    and creating observations from each of them. \n",
    "    \n",
    "    These observations are then all concatenated together \n",
    "    into one large dataframe\n",
    "    \n",
    "    Returns:\n",
    "        a pandas dataframe containing all data points (without any splits)\n",
    "    \"\"\"\n",
    "    \n",
    "    dataframes = []\n",
    "    \n",
    "    files = [file for file in os.listdir(AUDIO_PATH) if subset in file]\n",
    "\n",
    "    # Loop through all WAVs\n",
    "    for i, file in enumerate(files):\n",
    "        if file[-3:] != 'wav': \n",
    "            continue\n",
    "            \n",
    "        print(f'{subset} file {i+1}/{len(files)}', end='\\r')\n",
    "\n",
    "        path = os.path.join(AUDIO_PATH, file)\n",
    "        fs, wav_signals = wavfile.read(path)\n",
    "        \n",
    "        labels = (int(file.split('_')[2]), )\n",
    "        if file.split('_')[1] == 'angles':\n",
    "            labels = (int(file.split('_')[2]), int(file.split('_')[3]))\n",
    "            \n",
    "        X_temp = create_observations(wav_signals, labels, samples, step, resolution)\n",
    "        \n",
    "        cols = [f'mic{mic+1}_sample_{i}' for mic in range(MICS_NUMBER) for i in range(np.shape(X_temp)[2])]\n",
    "        \n",
    "        df = pd.DataFrame(data=np.reshape(X_temp, (len(X_temp), -1)), columns=cols)\n",
    "        \n",
    "        # Add extra info columns\n",
    "        if is_info:\n",
    "            room = file.split('_')[5 if file.split('_')[1] == 'angles' else 4]\n",
    "            df['room'] = room\n",
    "            \n",
    "        # Add label column\n",
    "        df['label'] = [labels] * len(df)\n",
    "        dataframes.append(df)\n",
    "        \n",
    "    return pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b4bb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train file 1998/1998\n",
      "test file 1998/1998\n",
      "(142560, 1536) (48222, 1536) (142560, 36) (48222, 36)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mic1_sample_0</th>\n",
       "      <th>mic1_sample_1</th>\n",
       "      <th>mic1_sample_2</th>\n",
       "      <th>mic1_sample_3</th>\n",
       "      <th>...</th>\n",
       "      <th>mic6_sample_254</th>\n",
       "      <th>mic6_sample_255</th>\n",
       "      <th>room</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-86</td>\n",
       "      <td>-88</td>\n",
       "      <td>large</td>\n",
       "      <td>(0, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4914</td>\n",
       "      <td>1346</td>\n",
       "      <td>-1934</td>\n",
       "      <td>-3557</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>-604</td>\n",
       "      <td>large</td>\n",
       "      <td>(0, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6909</td>\n",
       "      <td>-3849</td>\n",
       "      <td>-991</td>\n",
       "      <td>2880</td>\n",
       "      <td>...</td>\n",
       "      <td>-5123</td>\n",
       "      <td>-3551</td>\n",
       "      <td>large</td>\n",
       "      <td>(0, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10118</td>\n",
       "      <td>-8470</td>\n",
       "      <td>-5610</td>\n",
       "      <td>-4909</td>\n",
       "      <td>...</td>\n",
       "      <td>-5775</td>\n",
       "      <td>-7827</td>\n",
       "      <td>large</td>\n",
       "      <td>(0, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1084</td>\n",
       "      <td>1207</td>\n",
       "      <td>1565</td>\n",
       "      <td>1487</td>\n",
       "      <td>...</td>\n",
       "      <td>199</td>\n",
       "      <td>937</td>\n",
       "      <td>large</td>\n",
       "      <td>(0, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2520</td>\n",
       "      <td>-2133</td>\n",
       "      <td>-1787</td>\n",
       "      <td>-412</td>\n",
       "      <td>...</td>\n",
       "      <td>293</td>\n",
       "      <td>833</td>\n",
       "      <td>large</td>\n",
       "      <td>(0, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4860</td>\n",
       "      <td>4989</td>\n",
       "      <td>5798</td>\n",
       "      <td>3712</td>\n",
       "      <td>...</td>\n",
       "      <td>-631</td>\n",
       "      <td>4682</td>\n",
       "      <td>large</td>\n",
       "      <td>(0, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6202</td>\n",
       "      <td>5572</td>\n",
       "      <td>5322</td>\n",
       "      <td>4841</td>\n",
       "      <td>...</td>\n",
       "      <td>2623</td>\n",
       "      <td>2860</td>\n",
       "      <td>large</td>\n",
       "      <td>(0, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-10281</td>\n",
       "      <td>-8788</td>\n",
       "      <td>-8787</td>\n",
       "      <td>-9677</td>\n",
       "      <td>...</td>\n",
       "      <td>8960</td>\n",
       "      <td>9017</td>\n",
       "      <td>large</td>\n",
       "      <td>(0, 100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-3642</td>\n",
       "      <td>-3019</td>\n",
       "      <td>-2147</td>\n",
       "      <td>-461</td>\n",
       "      <td>...</td>\n",
       "      <td>1479</td>\n",
       "      <td>1461</td>\n",
       "      <td>large</td>\n",
       "      <td>(0, 100)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 1538 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mic1_sample_0  mic1_sample_1  mic1_sample_2  mic1_sample_3  ...  \\\n",
       "0              0              0              0              0  ...   \n",
       "1           4914           1346          -1934          -3557  ...   \n",
       "2          -6909          -3849           -991           2880  ...   \n",
       "3         -10118          -8470          -5610          -4909  ...   \n",
       "4           1084           1207           1565           1487  ...   \n",
       "5          -2520          -2133          -1787           -412  ...   \n",
       "6           4860           4989           5798           3712  ...   \n",
       "7           6202           5572           5322           4841  ...   \n",
       "8         -10281          -8788          -8787          -9677  ...   \n",
       "9          -3642          -3019          -2147           -461  ...   \n",
       "\n",
       "   mic6_sample_254  mic6_sample_255   room     label  \n",
       "0              -86              -88  large  (0, 100)  \n",
       "1              254             -604  large  (0, 100)  \n",
       "2            -5123            -3551  large  (0, 100)  \n",
       "3            -5775            -7827  large  (0, 100)  \n",
       "4              199              937  large  (0, 100)  \n",
       "5              293              833  large  (0, 100)  \n",
       "6             -631             4682  large  (0, 100)  \n",
       "7             2623             2860  large  (0, 100)  \n",
       "8             8960             9017  large  (0, 100)  \n",
       "9             1479             1461  large  (0, 100)  \n",
       "\n",
       "[10 rows x 1538 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = create_dataframe('train', samples=SAMPLES, step=STEP, resolution=RESOLUTION, interp=2)\n",
    "print()\n",
    "df_test = create_dataframe('test', samples=SAMPLES, step=STEP, resolution=RESOLUTION, interp=2)\n",
    "print()\n",
    "\n",
    "encoder = MultiLabelBinarizer()\n",
    "X_train, y_train, X_test, y_test = create_whole_dataset(df_train, df_test, encoder)\n",
    "\n",
    "print(np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))\n",
    "pd.set_option('display.max_columns', 8)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e5957f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "\n",
    "def custom_activation(x, axis=-1):\n",
    "    return tfa.seq2seq.hardmax(x)*x\n",
    "\n",
    "\n",
    "def deepmp(input_shape,SenMat,k):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    r = inputs\n",
    "    get_custom_objects().update({'custom_activation': custom_activation})\n",
    "\n",
    "    for kk in range(k):\n",
    "        if kk == 0:\n",
    "            denf1 = Dense(\n",
    "                SenMat.shape[1],\n",
    "                activation='custom_activation',\n",
    "                trainable=True,\n",
    "                use_bias=False,\n",
    "                weights=[SenMat]\n",
    "            )\n",
    "            \n",
    "            denb1 = Dense(\n",
    "                SenMat.shape[0],\n",
    "                trainable=False,\n",
    "                use_bias=False,\n",
    "                weights=[SenMat.transpose()]\n",
    "            )\n",
    "            \n",
    "            x = denf1(r)\n",
    "            rx = denb1(x)\n",
    "            r = keras.layers.subtract([r, rx])\n",
    "            z = x\n",
    "        else:\n",
    "            denf1 = Dense(\n",
    "                SenMat.shape[1],\n",
    "                activation='custom_activation',\n",
    "                trainable=True,\n",
    "                use_bias=False,\n",
    "                weights=[SenMat]\n",
    "            )\n",
    "            \n",
    "            x = denf1(r)\n",
    "            z = keras.layers.add([z,x])\n",
    "            rx = denb1(x)\n",
    "            r = keras.layers.subtract([r, rx])\n",
    "            \n",
    "    output = z    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4eac3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 1536 Output: 36\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 1536)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 36)           55296       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1536)         55296       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 1536)         0           input_2[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 36)           55296       subtract_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 36)           0           dense_3[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 165,888\n",
      "Trainable params: 110,592\n",
      "Non-trainable params: 55,296\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "k = 2  # sparsity of the signal\n",
    "m = X_train.shape[1]\n",
    "n = y_train.shape[1]\n",
    "\n",
    "print(f'Input: {m}', f'Output: {n}')\n",
    "\n",
    "M = np.array(np.abs(np.random.standard_normal((m, n))), dtype='float32')\n",
    "\n",
    "# Normalize the dictionary as implied by the standard procedure for Matching Pursuit Algorithms.\n",
    "for ii in range(0, M.shape[1]):\n",
    "    mind = M[:, ii] ** 2\n",
    "    no = mind.sum()\n",
    "    M[:, ii] = M[:, ii] / np.sqrt(no)\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "model = deepmp(input_shape=input_shape, SenMat=M, k=k)\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=sgd,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6255d53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4455/4455 [==============================] - 10s 2ms/step - loss: 30.2190 - accuracy: 0.0158\n",
      "Epoch 2/10\n",
      "4455/4455 [==============================] - 10s 2ms/step - loss: 30.1561 - accuracy: 0.0185\n",
      "Epoch 3/10\n",
      "4455/4455 [==============================] - 10s 2ms/step - loss: 30.1387 - accuracy: 0.0210\n",
      "Epoch 4/10\n",
      "4455/4455 [==============================] - 10s 2ms/step - loss: 30.1111 - accuracy: 0.0226\n",
      "Epoch 5/10\n",
      "4455/4455 [==============================] - 10s 2ms/step - loss: 30.0895 - accuracy: 0.0237\n",
      "Epoch 6/10\n",
      "4455/4455 [==============================] - 10s 2ms/step - loss: 30.0607 - accuracy: 0.0246\n",
      "Epoch 7/10\n",
      "4455/4455 [==============================] - 10s 2ms/step - loss: 30.0407 - accuracy: 0.0247\n",
      "Epoch 8/10\n",
      "4455/4455 [==============================] - 10s 2ms/step - loss: 30.0254 - accuracy: 0.0261\n",
      "Epoch 9/10\n",
      "4455/4455 [==============================] - 10s 2ms/step - loss: 30.0239 - accuracy: 0.0248\n",
      "Epoch 10/10\n",
      "4455/4455 [==============================] - 10s 2ms/step - loss: 30.0114 - accuracy: 0.0245\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "977c1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
