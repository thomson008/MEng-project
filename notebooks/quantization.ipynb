{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df31a54e",
   "metadata": {},
   "source": [
    "# Model quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd269475",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D, Conv2D\n",
    "from keras.layers import MaxPooling1D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "541d794c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((628560, 13, 15, 1), (210740, 13, 15, 1), (628560, 36), (210740, 36))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../training_data/azimuth_train_dataset.csv', index_col=[0])\n",
    "df_test = pd.read_csv('../training_data/azimuth_test_dataset.csv', index_col=[0])\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "encoder.fit([[label] for label in df_train['label']])\n",
    "X_train, y_train, X_test, y_test = create_whole_dataset(df_train, df_test, encoder)\n",
    "\n",
    "X_train, X_test = np.transpose(np.array([X_train]), axes=[1, 3, 2, 0]), np.transpose(np.array([X_test]), axes=[1, 3, 2, 0])\n",
    "\n",
    "np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf86105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "epochs, batch_size, verbose = 3, 32, 1\n",
    "\n",
    "def create_model(X_train, y_train, X_test, y_test):\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "\n",
    "    # Init model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add layers\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features,1)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    q_aware_model = quantize_model(model)\n",
    "    q_aware_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return q_aware_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "247fa402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "19643/19643 [==============================] - 173s 9ms/step - loss: 0.1769 - accuracy: 0.9319\n",
      "Epoch 2/3\n",
      "19643/19643 [==============================] - 172s 9ms/step - loss: 0.0872 - accuracy: 0.9662\n",
      "Epoch 3/3\n",
      "19643/19643 [==============================] - 172s 9ms/step - loss: 0.0703 - accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "model, history = create_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6ff7377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "quantize_layer (QuantizeLaye (None, 13, 15, 1)         3         \n",
      "_________________________________________________________________\n",
      "quant_conv2d_2 (QuantizeWrap (None, 11, 13, 64)        771       \n",
      "_________________________________________________________________\n",
      "quant_conv2d_3 (QuantizeWrap (None, 9, 11, 64)         37059     \n",
      "_________________________________________________________________\n",
      "quant_dropout_1 (QuantizeWra (None, 9, 11, 64)         1         \n",
      "_________________________________________________________________\n",
      "quant_max_pooling2d_1 (Quant (None, 4, 5, 64)          1         \n",
      "_________________________________________________________________\n",
      "quant_flatten_1 (QuantizeWra (None, 1280)              1         \n",
      "_________________________________________________________________\n",
      "quant_dense_2 (QuantizeWrapp (None, 100)               128105    \n",
      "_________________________________________________________________\n",
      "quant_dense_3 (QuantizeWrapp (None, 36)                3641      \n",
      "=================================================================\n",
      "Total params: 169,582\n",
      "Trainable params: 169,304\n",
      "Non-trainable params: 278\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca64e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_2_layer_call_and_return_conditional_losses, conv2d_2_layer_call_fn, conv2d_3_layer_call_and_return_conditional_losses, conv2d_3_layer_call_fn, dropout_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tkhor\\AppData\\Local\\Temp\\tmp20yguavg\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\tkhor\\AppData\\Local\\Temp\\tmp20yguavg\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the Lite model.\n",
    "with open('../models/quant_azimuth_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
